#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Continuously read assembled logs and filter for ASCII payloads with "wget"
or "curl" in them.

Publishes messages under given topics which are JSON decodeable with the
following keys:
"ts", "tag", "saddr", "daddr", "sport", "dport", "payload", "tool", "decoded",

Example: mwfk -c bcix-nt -p bcix-nt
"""

__maintainer__ = "Raphael Hiesgen"
__email__ = "raphael.hiesgen@haw-hamburg.de"
__copyright__ = "Copyright 2018-2021"

import click
import csv
import json

from kafka import KafkaProducer, KafkaConsumer


# -- payload checks -----------------------------------------------------------

ascii_min = 33
ascii_max = 126

other_acsii = [
    0,  # nul
    9,  # horizontal tab
    10,  # new line
    13,  # carriage return
    32,  # space
]


def estimate_decodability(pl, length=15):
    in_ascii_range = 0
    not_in_ascii_range = 0
    range_end = min(len(pl), length * 2)
    for i in range(0, range_end, 2):
        lhs = pl[i]
        rhs = pl[i + 1]
        decoded = int(lhs + rhs, 16)
        # print(f'decoded {lhs + rhs}Â to {decoded}')
        if (ascii_min <= decoded <= ascii_max) or (decoded in other_acsii):
            in_ascii_range += 1
        else:
            not_in_ascii_range += 1
    # Check if more than 2/3 of pl are ASCII (len of pl is already twice the
    # characters).
    # threshold = range_end / 3
    # print(f'{in_ascii_range} / {threshold} ({not_in_ascii_range})')
    # if in_ascii_range >= threshold:
    if in_ascii_range >= not_in_ascii_range:
        return True
    else:
        return False


def manual_decode(pl):
    string = ""
    for i in range(0, len(pl), 2):
        lhs = pl[i]
        rhs = pl[i + 1]
        decoded = int(lhs + rhs, 16)
        string += chr(decoded)
    return string


def decode_hex(pl):
    # should_be_decodable = estimate_decodability(pl)
    try:
        decoded = bytearray.fromhex(pl).decode()
        # if not should_be_decodable:
        # print(
        # f'looks like I was wrong (is decodedable): "{pl}" --> "{decoded}"')
        return decoded
    except Exception:
        # if should_be_decodable:
        # print(f'looks like I was wrong (is NOT decodedable): {pl}')
        # print(f' > {manual_decode(pl)}')
        return None


@click.command()
@click.option(
    "-c",
    "--consume",
    "consume_me",
    type=str,
    default=None,
    required=True,
    multiple=True,
    help="match phases for this datasource",
)
@click.option(
    "-p",
    "--produce",
    "produce_me",
    type=str,
    default=None,
    help="match phases for this datasource",
)
@click.option(
    "-k",
    "--kafka-port",
    "kafka_port",
    type=int,
    default=9092,
    help="port of the local kafka server (default: 9092)",
)
@click.option(
    "--kafka-batch-size",
    "kafka_batch_size",
    type=int,
    default=1,
    help="batch size for sending produced events (default: 1)",
)
def main(consume_me, produce_me, kafka_port, kafka_batch_size):

    kafka_consumer_topics = [f"cse2.malware.events.{ds}" for ds in consume_me]
    kafka_producer_topic = "cse2.malware.filtered"
    if produce_me is not None and len(produce_me) > 0:
        kafka_producer_topic += f".{produce_me}"
    kafka_group_id = "cse2.mw.filtering"

    print(f"consuming from '{kafka_consumer_topics}'")
    print(f"publishing to '{kafka_producer_topic}'")

    consumer = KafkaConsumer(
        group_id=kafka_group_id,
        bootstrap_servers=[f"localhost:{kafka_port}"],
        # The value deserializer seems to deserialize the whole message and
        # not just the value ...
        # value_deserializer=lambda x: json.loads(x.decode("utf-8")),
    )
    consumer.subscribe(kafka_consumer_topics)

    producer = KafkaProducer(
        bootstrap_servers=[f"localhost:{kafka_port}"],
        batch_size=kafka_batch_size,
        value_serializer=lambda x: json.dumps(x).encode("utf-8"),
    )

    def check(event, packet_type):
        if packet_type in event and event[packet_type] is not None:
            # Get the packet information of the IP header
            ip = event[packet_type]["trigger"]
            if ip["proto"] == "tcp" and ip["payload"] is not None:
                tcp = ip["payload"]
                payload = tcp["payload"]
                if payload != "" and len(payload) > 0:
                    decoded = decode_hex(payload)
                    if decoded is not None:
                        tool = None
                        if "wget" in decoded:
                            tool = "wget"
                        elif "curl" in decoded:
                            tool = "curl"
                        if tool is not None:
                            ts = ip["timestamp"]
                            d = {
                                "ts": ts,
                                "tag": event["tag"],
                                "saddr": ip["saddr"],
                                "daddr": ip["daddr"],
                                "sport": tcp["sport"],
                                "dport": tcp["dport"],
                                "payload": payload,
                                "tool": tool,
                                "decoded": repr(decoded),
                            }
                            return d
        return None


    consumed = 0
    produced = 0
    while True:
        for msg in consumer:
            event = json.loads(msg.value.decode("utf-8"))
            consumed += 1
            # print(f'now analyzing: {event}')
            elem = check(event, "rack")
            if elem is None:
                # Maybe there is a payload for an ack to an irregular syn?
                elem = check(event, "iack")
            # No else! If we did not find wget or curl in the payload we pass
            # it on.
            if elem is not None:
                producer.send(kafka_producer_topic, elem)
                produced += 1
            if consumed % 100000 == 0:
                print(f"[DBG] consumed = {consumed}, produced = {produced}")


if __name__ == "__main__":
    main()
