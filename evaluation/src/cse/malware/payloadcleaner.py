#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Clean payloads and extract the download URL.
"""

__maintainer__ = "Raphael Hiesgen"
__email__ = "raphael.hiesgen@haw-hamburg.de"
__copyright__ = "Copyright 2018-2021"

import argparse

from urllib.parse import unquote_plus, urlparse


# -- helper ------------------------------------------------------

def log_error(filename, message):
    with open(filename, "at") as fh:
        fh.write(message + '\n')

def is_url(x):
    try:
        result = urlparse(x)
        return all([result.scheme, result.netloc]) # , result.path
    except Exception:
        return False

def find_substrings_starting_with(needle, haystack):
    pos = 0
    matches = []
    if len(needle) == 0:
        return matches
    while True:
        pos = haystack.find(needle, pos)
        if pos == -1:
            break
        matches.append(pos)
        pos += len(needle)
    substrings = []
    if len(matches) >= 1:
        matches.append(len(haystack))
        for i in range(0, len(matches) - 1):
            substrings.append(haystack[matches[i]:matches[i+1]])
    return substrings

# Source: https://stackoverflow.com/a/2556252
def rreplace(s, old, new, occurrence=1):
    li = s.rsplit(old, occurrence)
    return new.join(li)

# -- cleaning ----------------------------------------------------

def clean_pl(pl):
    pl = unquote_plus(pl)
    pl = pl.replace(";", " ")
    pl = pl.replace("`", " ")
    pl = pl.replace("+", " ")
    pl = pl.replace("${IFS}", " ")
    pl = pl.replace("\r", " ")
    pl = pl.replace("\n", " ")
    pl = pl.replace("\t", " ")
    pl = pl.replace("\\r", " ")
    pl = pl.replace("\\n", " ")
    pl = pl.replace("\\t", " ")
    pl = pl.replace("'", " ")
    pl = pl.replace("(", " ")
    pl = pl.replace("\\", "")
    pl = pl.replace("http:// ", "http://")
    pl = pl.replace("https:// ", "https://")
    pl = pl.replace("  ", " ")
    pl = pl.replace("&", " ")
    pl = pl.lstrip()
    pl = pl.rstrip()
    return pl

def extract_name(url):
    name = None
    if "/" in url:
        parts = url.split("/")
        name = parts[-1]
    else:
        print(f"[NAME] encountered URL without name: {url}")
        name = url  # TODO: add a fake name
    return name

def clean(tool, pl, args_parser_fun):
    # Needs to be configured with a parser funciton. The ones for wget and curl are below.
    substrings = find_substrings_starting_with(tool, pl)
    # print(f"[PC] found {len(substrings)} substrings for {tool}")
    results = []
    for substr in substrings:
        substr = substr.lstrip('tool')
        # print(f"> '{substr}'")
        if substr == "":
            continue

        url = args_parser_fun(substr)
        
        if url is None or url == "":
            continue

        if not url.startswith("http://"):
            url = "http://" + url
        server = urlparse(url).netloc

        port = 80
        if ":" in server:
            parts = server.split(":")
            if len(parts) == 2:
                server = parts[0]
                port = parts[1]
        # print(f"{tool}|{url}|{server}|{port}")
        # build event
        info = {
            "tool": tool,
            "url": url,
            "server": server,
            "port": port,
            "name": extract_name(url),
        }
        results.append(info)
    if len(results) == 0:
        print(f"[PARSE] failed find URL in '{pl}'")
    return results

def parse_wget_args(args):
    # print(f"[WGET] with '{args}'")
    if args.startswith('wget'):
        args = args.replace('wget', '', 1)
    args = args.lstrip()
    if args == "":
        return ""

    parts = args.strip().split(" ")
    
    # Check if the first argument is a url. In that case there won't be any other arguments.
    if is_url(parts[0]):
        return parts[0]

    # If the first arg is not a URL, let's get parsing!
    ap = argparse.ArgumentParser(prog="WGET-parsing")
    ap.add_argument('remainder', type=str, nargs='*')
    ap.add_argument("-g", "--ghost", type=str)
    ap.add_argument("-l", "--local-path", type=str)
    ap.add_argument("-r", "--remote-path", type=str)
    ap.add_argument("-O", "--out-name", type=str)
    ap.add_argument("-U", "--user-agent", type=str)
    ap.add_argument("-q", "--quiet", action="store_true")
    ap.add_argument("-rf", action='store_true')  # hack to dodge "rm -rf"

    opts, unknown = ap.parse_known_args(parts)
    if unknown is not None and len(unknown) > 0:
        print(f"[WGET] Unknown arguments: '{unknown}'")

    url = ""
    local_name = ""
    user_agent = ""

    # Find host
    if opts.ghost is not None and opts.ghost != "":
        if opts.ghost.startswith("http"):
            url = opts.ghost
        else:
            url = "http://" + opts.ghost
    else:
        # Should be the first argument right?
        elem = opts.remainder[0]
        if elem.startswith("http"):
            url = elem
        else:
            url = "http://" + elem
        
    if not is_url(url):
        return None

    # Path
    if opts.remote_path is not None and opts.remote_path != "":
        path = opts.remote_path
        if url.endswith('/') or path.startswith('/'):
            url += path
        else:
            url += '/'
            url += path
        # print(f"[WGET] explicit path: '{path}'")

    # Does the local name differ?
    if opts.local_path is not None and opts.local_path != "":
        local_path = opts.local_path
        if '/' in local_path:
            parts = local_path.split('/')
            local_name = parts[-1]
        else:
            local_name = local_path
        # print(f"[WGET] explicit local name: '{local_name}'")

    if opts.user_agent is not None and opts.user_agent != "":
        user_agent = opts.user_agent
        # print(f"[WGET] explicit user agent '{user_agent}'")

    # print(f"[WGET] parsed '{url}'")
    return url

def parse_curl_args(args):
    # print(f"[CURL] with '{args}'")
    if args.startswith('curl'):
        args = args.replace('curl', '', 1)
    args = args.lstrip()
    if args == "":
        return None

    parts = args.strip().split(" ")
    
    # Check if the first argument is a url. In that case there won't be any other arguments.
    if is_url(parts[0]):
        return parts[0]

    # If the first arg is not a URL, let's get parsing!
    ap = argparse.ArgumentParser(prog="CURL-parsing")
    ap.add_argument('remainder', type=str, nargs='*')
    ap.add_argument("-O", action='store_true')
    ap.add_argument("-f", "--fail-silently", action='store_true')
    ap.add_argument("-s", "--silent-mode", action='store_true')
    ap.add_argument("-S", "--show-error", action='store_true')
    ap.add_argument("-L", "--location", action='store_true')
    ap.add_argument("-A", "--user-agent", type=str)

    opts, unknown = ap.parse_known_args(parts)
    if unknown is not None and len(unknown) > 0:
        print(f"[CURL] Unknown arguments: '{unknown}'")

    url = ""
    user_agent = ""

    # Find host
    elem = opts.remainder[0]
    if elem.startswith("http"):
        url = elem
    else:
        url = "http://" + elem

    if not is_url(url):
        return None

    if opts.user_agent is not None and opts.user_agent != "":
        user_agent = opts.user_agent
        # print(f"[CURL] explicit user agent '{user_agent}'")

    # print(f"[CURL] parsed '{url}'")
    return url

# -- class -------------------------------------------------------

class PayloadCleaner:

    def __init__(self, payload, logfile=None) -> None:
        self.payload = clean_pl(payload)
        self.logfile = logfile

        self.contains_wget = False
        self.contains_curl = False

        if "wget" in self.payload:
            self.contains_wget = True
            if self.payload.endswith("wget"):
                self.payload = rreplace(self.payload, "wget", "")
                if "wget" not in self.payload:
                    self.contains_wget = False


        if "curl" in self.payload:
            if self.payload.endswith("curl"):
                self.payload = rreplace(self.payload, "curl", "")
            pos = self.payload.find("User-Agent: curl")
            if pos != -1:
                self.payload = self.payload.replace("User-Agent: curl", "")
            pos = self.payload.find(" libcurl/")
            if pos != -1:
                self.payload = self.payload.replace(" libcurl/", "")
            if "curl" in self.payload:
               self.contains_curl = True

        # print(f"[PC] '{payload}' with {self.contains_wget}/{self.contains_curl}")


    def get_urls(self):
        expected_results = 0

        # Check wget
        results = []
        if self.contains_wget:
            expected_results += 1
            elems = clean("wget", self.payload, parse_wget_args)
            if elems is not None and len(elems) > 0:
                if len(elems) > 1:
                    expected_results += len(elems)
                    expected_results -= 1
                results.extend(elems)

        # Check curl
        if self.contains_curl:
            expected_results += 1
            elems = clean("curl", self.payload, parse_curl_args)
            if elems is not None and len(elems) > 0:
                if len(elems) > 1:
                    expected_results += len(elems)
                    expected_results -= 1
                results.extend(elems)

        if len(results) != expected_results:
            if self.logfile is not None:
                log_error(self.logfile, f"[ERR] Failed to parse downloader from '{self.payload}'")
        return results

